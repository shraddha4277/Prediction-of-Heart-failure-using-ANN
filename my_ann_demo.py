# -*- coding: utf-8 -*-
"""My_ANN_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ki1aHLzKPuYQP6uWFTIDEIF12iB0b5yT
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.layers import Dense, BatchNormalization, Dropout
from keras.models import Sequential
from keras.utils import to_categorical
from keras import callbacks
from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score

data = pd.read_csv('/content/heart_failure_clinical_records_dataset.csv')

data.sample(10)

data.info()

"""DATA ANALYSIS"""

# Create count plot
cols = ["red", "orange"]
# Create count plot with hue and legend parameters
sns.countplot(x=data["DEATH_EVENT"], hue=data["DEATH_EVENT"], palette=cols, legend=False)

data['diabetes'].value_counts()

#corelation matrix of all the features
corr_matrix = data.corr()
plt.subplots(figsize=(15,15))
sns.heatmap(corr_matrix, annot=True)

#Evauating age distribution
plt.figure(figsize=(40,12))
Days_of_week=sns.countplot(x=data['age'],data=data, hue ="DEATH_EVENT",palette = cols)
Days_of_week.set_title("Distribution Of Age")

# analysis some non binary features.
feature = ["age","creatinine_phosphokinase","ejection_fraction","platelets","serum_creatinine","serum_sodium", "time"]
for i in feature:
  sns.distplot(data[i],hist=False)
  plt.title(i)
  plt.show()

feature = ["age","creatinine_phosphokinase","ejection_fraction","platelets","serum_creatinine","serum_sodium", "time"]
for i in feature:
    plt.figure(figsize=(8,8))
    sns.swarmplot(x=data["DEATH_EVENT"], y=data[i], color="black", alpha=0.5)
    sns.boxenplot(x=data["DEATH_EVENT"], y=data[i], palette=cols)
    plt.show()

data.describe().T

"""DATA PREPROCESSING"""

x = data.drop('DEATH_EVENT', axis=1)
y = data['DEATH_EVENT']
#In pandas, axis=0 refers to rows and axis=1 refers to columns.

#Set up a standard scaler for the features
col_names = list(x.columns)
s_scaler = preprocessing.StandardScaler()
#standardizes the data, meaning it transforms the data to have a mean of 0 and a standard deviation of 1.
x_df= s_scaler.fit_transform(x)
x_df = pd.DataFrame(x_df, columns=col_names)#standardized data is then converted back to a DataFrame
x_df.describe().T

plt.figure(figsize=(10,10))
sns.boxenplot(data=x_df)
# Rotate x-axis tick labels by 90 degrees
plt.xticks(rotation=90)
plt.show

#spliting test and training sets
x_train, x_test, y_train,y_test = train_test_split(x_df,y,test_size=0.25,random_state=7)

"""MODEL"""

early_stopping = callbacks.EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True)

# Initialising the NN
model = Sequential()# provides a simple way to build and train neural network models layer by layer

#Input layer
model.add(Dense(units=16, kernel_initializer='uniform', activation='relu', input_dim=x_train.shape[1]))
model.add(Dense(units=8, kernel_initializer='uniform', activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=4, kernel_initializer='uniform', activation='relu'))
model.add(Dropout(0.5))
# Output layer for binary classification
model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Step 4: Train the Model
history = model.fit(x_train, y_train, batch_size=32, epochs=500, validation_split=0.2)

val_accuracy = np.mean(history.history['val_accuracy'])
print("\n%s: %.2f%%" % ('val_accuracy', val_accuracy*100))